#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é«˜çº§æ£€ç´¢ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨é«˜çº§æ£€ç´¢åŠŸèƒ½
"""

from scholar_crawler import ScholarCrawler
from config import AdvancedSearchConfig
from config_manager import ConfigManager
import time


def example_1_year_range():
    """ç¤ºä¾‹1: æŒ‰å¹´ä»½èŒƒå›´æœç´¢"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1: æœç´¢2020-2023å¹´çš„æ·±åº¦å­¦ä¹ æ–‡çŒ®")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.year_start = 2020
    config.year_end = 2023
    config.citations_min = 30
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("deep learning", max_results=20, 
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example1_year_range.csv", 
                             "deep learning (2020-2023)")


def example_2_top_authors():
    """ç¤ºä¾‹2: æœç´¢ç‰¹å®šä½œè€…çš„æ–‡çŒ®"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2: æœç´¢å›¾çµå¥–å¾—ä¸»çš„æ·±åº¦å­¦ä¹ æ–‡çŒ®")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.authors = ["Yann LeCun", "Geoffrey Hinton", "Yoshua Bengio"]
    config.citations_min = 50
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("deep learning", max_results=20,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example2_top_authors.csv",
                             "deep learning (é¡¶çº§ä½œè€…)")


def example_3_top_venues():
    """ç¤ºä¾‹3: æœç´¢é¡¶ä¼šæ–‡çŒ®"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3: æœç´¢é¡¶çº§AIä¼šè®®çš„è®¡ç®—æœºè§†è§‰æ–‡çŒ®")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.venues = ["CVPR", "ICCV", "ECCV"]
    config.year_start = 2021
    config.citations_min = 40
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("computer vision", max_results=25,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example3_top_venues.csv",
                             "computer vision (é¡¶ä¼š)")


def example_4_exclude_reviews():
    """ç¤ºä¾‹4: æ’é™¤ç»¼è¿°ç±»æ–‡ç« """
    print("\n" + "="*60)
    print("ç¤ºä¾‹4: æœç´¢æœºå™¨å­¦ä¹ æ–‡çŒ®ï¼Œæ’é™¤ç»¼è¿°ç±»æ–‡ç« ")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.exclude_keywords = ["survey", "review", "tutorial"]
    config.citations_min = 30
    config.year_start = 2020
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("machine learning", max_results=20,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example4_exclude_reviews.csv",
                             "machine learning (éç»¼è¿°)")


def example_5_high_impact():
    """ç¤ºä¾‹5: æœç´¢çªç ´æ€§è®ºæ–‡"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹5: æœç´¢é«˜å½±å“åŠ›çš„transformerç›¸å…³è®ºæ–‡ï¼ˆå¼•ç”¨>=200ï¼‰")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.citations_min = 200
    config.year_start = 2017
    config.additional_keywords = ["transformer", "attention"]
    config.keyword_mode = "OR"
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("neural networks", max_results=15,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example5_high_impact.csv",
                             "transformer (é«˜å½±å“)")


def example_6_load_config_file():
    """ç¤ºä¾‹6: ä»é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹6: ä½¿ç”¨é…ç½®æ–‡ä»¶æœç´¢")
    print("="*60)
    
    manager = ConfigManager()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    config_path = "configs/top_ai_conferences.json"
    try:
        config = manager.load_config(config_path)
        print(f"âœ“ å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        print(config)
        
        crawler = ScholarCrawler(use_proxy=False)
        papers = crawler.search_papers("reinforcement learning", max_results=20,
                                       advanced_config=config)
        
        if papers:
            papers = crawler.sort_by_citations(papers)
            crawler.export_to_csv(papers, "results/example6_config_file.csv",
                                 "reinforcement learning (é…ç½®æ–‡ä»¶)")
    
    except FileNotFoundError:
        print(f"âš  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print("è¯·å…ˆåˆ›å»ºé…ç½®æ–‡ä»¶æˆ–ä½¿ç”¨å…¶ä»–ç¤ºä¾‹")


def example_7_comprehensive():
    """ç¤ºä¾‹7: ç»¼åˆé«˜çº§æ£€ç´¢"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹7: ç»¼åˆæ£€ç´¢ - 2021-2023å¹´é¡¶ä¼šé«˜å¼•ç”¨GANæ–‡çŒ®")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.year_start = 2021
    config.year_end = 2023
    config.venues = ["NeurIPS", "ICML", "ICLR", "CVPR", "ICCV"]
    config.citations_min = 50
    config.additional_keywords = ["GAN", "generative"]
    config.exclude_keywords = ["survey", "review"]
    config.keyword_mode = "OR"
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("image generation", max_results=20,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example7_comprehensive.csv",
                             "image generation (ç»¼åˆæ£€ç´¢)")


def example_8_publishers():
    """ç¤ºä¾‹8: æŒ‰å‡ºç‰ˆå•†ç­›é€‰"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹8: æœç´¢IEEEå’ŒACMå‡ºç‰ˆçš„æ·±åº¦å­¦ä¹ æ–‡çŒ®")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.publishers = ["IEEE", "ACM"]
    config.year_start = 2020
    config.citations_min = 25
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("deep learning", max_results=20,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example8_publishers.csv",
                             "deep learning (IEEE/ACM)")


def example_9_citation_range():
    """ç¤ºä¾‹9: æŒ‰å¼•ç”¨é‡èŒƒå›´ç­›é€‰"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹9: æœç´¢ä¸­ç­‰å½±å“åŠ›æ–‡çŒ®ï¼ˆå¼•ç”¨é‡50-200ï¼‰")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.citations_min = 50
    config.citations_max = 200
    config.year_start = 2020
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("neural networks", max_results=20,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example9_citation_range.csv",
                             "neural networks (ä¸­ç­‰å½±å“)")


def example_10_keyword_modes():
    """ç¤ºä¾‹10: å…³é”®å­—ANDæ¨¡å¼"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹10: åŒæ—¶åŒ…å«å¤šä¸ªå…³é”®å­—ï¼ˆANDæ¨¡å¼ï¼‰")
    print("="*60)
    
    config = AdvancedSearchConfig()
    config.additional_keywords = ["neural", "optimization", "training"]
    config.keyword_mode = "AND"  # å¿…é¡»åŒæ—¶åŒ…å«æ‰€æœ‰å…³é”®å­—
    config.citations_min = 30
    
    crawler = ScholarCrawler(use_proxy=False)
    papers = crawler.search_papers("deep learning", max_results=15,
                                   advanced_config=config)
    
    if papers:
        papers = crawler.sort_by_citations(papers)
        crawler.export_to_csv(papers, "results/example10_keyword_and.csv",
                             "deep learning (ANDæ¨¡å¼)")


def run_all_examples():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    examples = [
        ("ç¤ºä¾‹1: å¹´ä»½èŒƒå›´", example_1_year_range),
        ("ç¤ºä¾‹2: ç‰¹å®šä½œè€…", example_2_top_authors),
        ("ç¤ºä¾‹3: é¡¶ä¼šç­›é€‰", example_3_top_venues),
        ("ç¤ºä¾‹4: æ’é™¤ç»¼è¿°", example_4_exclude_reviews),
        ("ç¤ºä¾‹5: é«˜å½±å“åŠ›", example_5_high_impact),
        ("ç¤ºä¾‹6: é…ç½®æ–‡ä»¶", example_6_load_config_file),
        ("ç¤ºä¾‹7: ç»¼åˆæ£€ç´¢", example_7_comprehensive),
        ("ç¤ºä¾‹8: å‡ºç‰ˆå•†", example_8_publishers),
        ("ç¤ºä¾‹9: å¼•ç”¨èŒƒå›´", example_9_citation_range),
        ("ç¤ºä¾‹10: ANDæ¨¡å¼", example_10_keyword_modes),
    ]
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        é«˜çº§æ£€ç´¢ç¤ºä¾‹é›† - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

è­¦å‘Šï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹å°†éœ€è¦è¾ƒé•¿æ—¶é—´
å»ºè®®ï¼šé¦–æ¬¡ä½¿ç”¨è¯·é€‰æ‹©å•ä¸ªç¤ºä¾‹è¿è¡Œ
""")
    
    confirm = input("ç¡®è®¤è¿è¡Œæ‰€æœ‰ç¤ºä¾‹ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆ")
        return
    
    for i, (name, func) in enumerate(examples, 1):
        print(f"\n[{i}/{len(examples)}] è¿è¡Œ {name}")
        print("-" * 60)
        
        try:
            func()
            
            # åœ¨ç¤ºä¾‹ä¹‹é—´æ·»åŠ å»¶è¿Ÿ
            if i < len(examples):
                print("\nâ³ ç­‰å¾…5ç§’åç»§ç»­ä¸‹ä¸€ä¸ªç¤ºä¾‹...")
                time.sleep(5)
        
        except KeyboardInterrupt:
            print("\n\nâš  ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
            continue
    
    print("\n" + "="*60)
    print("âœ“ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("ğŸ“ ç»“æœå·²ä¿å­˜åˆ° results/ ç›®å½•")
    print("="*60)


def main():
    """ä¸»èœå•"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            é«˜çº§æ£€ç´¢ä½¿ç”¨ç¤ºä¾‹ ğŸ“š                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹:

  1.  ç¤ºä¾‹1: æŒ‰å¹´ä»½èŒƒå›´æœç´¢ (2020-2023)
  2.  ç¤ºä¾‹2: æœç´¢ç‰¹å®šä½œè€… (å›¾çµå¥–å¾—ä¸»)
  3.  ç¤ºä¾‹3: æœç´¢é¡¶ä¼šæ–‡çŒ® (CVPR/ICCV/ECCV)
  4.  ç¤ºä¾‹4: æ’é™¤ç»¼è¿°ç±»æ–‡ç« 
  5.  ç¤ºä¾‹5: æœç´¢çªç ´æ€§è®ºæ–‡ (å¼•ç”¨>=200)
  6.  ç¤ºä¾‹6: ä»é…ç½®æ–‡ä»¶åŠ è½½
  7.  ç¤ºä¾‹7: ç»¼åˆé«˜çº§æ£€ç´¢
  8.  ç¤ºä¾‹8: æŒ‰å‡ºç‰ˆå•†ç­›é€‰ (IEEE/ACM)
  9.  ç¤ºä¾‹9: æŒ‰å¼•ç”¨é‡èŒƒå›´ç­›é€‰ (50-200)
  10. ç¤ºä¾‹10: å…³é”®å­—ANDæ¨¡å¼

  0.  è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
  99. é€€å‡º

""")
    
    choice = input("è¯·é€‰æ‹© (0-10, 99): ").strip()
    
    examples = {
        '1': example_1_year_range,
        '2': example_2_top_authors,
        '3': example_3_top_venues,
        '4': example_4_exclude_reviews,
        '5': example_5_high_impact,
        '6': example_6_load_config_file,
        '7': example_7_comprehensive,
        '8': example_8_publishers,
        '9': example_9_citation_range,
        '10': example_10_keyword_modes,
        '0': run_all_examples,
    }
    
    if choice in examples:
        examples[choice]()
    elif choice == '99':
        print("å†è§!")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nå†è§! ğŸ‘‹")

